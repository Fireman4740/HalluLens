# Core API config
OPENROUTER_API_KEY=                 # OpenRouter API key
OPENROUTER_HTTP_REFERER=http://localhost    # Optional: OpenRouter analytics referrer
OPENROUTER_APP_TITLE=HalluLens              # Optional: OpenRouter app title
OPENROUTER_MODEL=                           # Optional: default model override

# Optional LM Studio config (set USE_LM_STUDIO=true to enable)
USE_LM_STUDIO=false                         # true=use LM Studio instead of OpenRouter
LM_STUDIO_URL=http://10.10.12.21:1234/v1/chat/completions  # LM Studio endpoint
LM_STUDIO_MODEL=openai/gpt-oss-20b          # LM Studio model name

# Global experiment config
EXP_MODE=longwiki                            # longwiki or hybrid
N=1                                          # number of prompts to generate
DB_PATH=data/wiki_data/.cache/enwiki-20230401.db  # SQLite DB for retrieval/eval

# ===== Prompt generation (LongWiki / Hybrid) =====
MODEL_PROMPT=openai/gpt-oss-safeguard-20b    # model used to generate prompts
TASKS=INTERVIEW NEWS_ARTICLE                 # task list (space-separated)
CREATIVITY=FACTUAL HYBRID VERY_CREATIVE      # creativity levels (space-separated)
LENGTH_WORDS=100                              # target length for prompts
LOW_LEVEL=5                                  # min h_score_cat
HIGH_LEVEL=10                                # max h_score_cat (exclusive)
STATIC_USER_PROMPT=false                     # true=deterministic prompt template

# ===== Inference (model under test) =====
MODEL_RESPONSE=mistralai/mistral-small-creative  # model being evaluated
INFERENCE_METHOD=custom                          # custom/openai/vllm
TEMPERATURE=0.0                                  # decoding temperature
MAX_TOKENS=1024                                  # max tokens per response
MAX_WORKERS=64                                   # parallel requests

# ===== Evaluation (hallucination scoring) =====
MODEL_EVAL=openai/gpt-oss-safeguard-20b          # default eval model
ABSTAIN_EVALUATOR=openai/gpt-oss-safeguard-20b   # refusal/abstain checker
CLAIM_EXTRACTOR=openai/gpt-oss-safeguard-20b     # claim extraction model
VERIFIER=openai/gpt-oss-safeguard-20b            # claim verification model
K=32                                             # top-k evidence for recall
EVAL_CACHE_PATH=                                 # optional cache dir
